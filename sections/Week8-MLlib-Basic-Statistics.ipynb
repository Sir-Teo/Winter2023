{"cells": [{"cell_type": "markdown", "id": "05126f06-fd4d-40b8-8082-2d50d9bc3fe0", "metadata": {}, "source": "# MLlib Basic Statistics\nSource link: https://spark.apache.org/docs/3.1.3/ml-statistics.html"}, {"cell_type": "markdown", "id": "541e5e8d-fa3a-4fd1-8d2a-792cff3cd013", "metadata": {}, "source": "\n**Table of Contents**\n\n1. [Correlation](#Correlation)\n2. [Hypothesis Testing](#Hypothesis)\n    1. [ChiSquareTest](#ChiSquareTest)\n3. [Summarizer](#Summarizer)"}, {"cell_type": "markdown", "id": "d086dea9-2c85-49a4-ba89-9f4aa41cc60f", "metadata": {}, "source": "## Correlation <a name=\"Correlation\"></a>\nCalculating the correlation between two series of data is a common operation in Statistics. In spark.ml we provide the flexibility to calculate pairwise correlations among many series. The supported correlation methods are currently Pearson's and Spearman's correlation.\n\n[Correlation](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.stat.Correlation.html) computes the correlation matrix for the input Dataset of Vectors using the specified method. The output will be a DataFrame that contains the correlation matrix of the column of vectors."}, {"cell_type": "code", "execution_count": 8, "id": "0f8ecc97-dd82-47c2-a85e-6ea0cdb41826", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/02/26 00:38:29 WARN org.apache.spark.mllib.stat.correlation.PearsonCorrelation: Pearson correlation matrix contains NaN values.\n"}, {"name": "stdout", "output_type": "stream", "text": "Pearson correlation matrix:\nDenseMatrix([[1.        , 0.05564149,        nan, 0.40047142],\n             [0.05564149, 1.        ,        nan, 0.91359586],\n             [       nan,        nan, 1.        ,        nan],\n             [0.40047142, 0.91359586,        nan, 1.        ]])\nSpearman correlation matrix:\nDenseMatrix([[1.        , 0.10540926,        nan, 0.4       ],\n             [0.10540926, 1.        ,        nan, 0.9486833 ],\n             [       nan,        nan, 1.        ,        nan],\n             [0.4       , 0.9486833 ,        nan, 1.        ]])\n"}, {"name": "stderr", "output_type": "stream", "text": "23/02/26 00:38:30 WARN org.apache.spark.mllib.stat.correlation.PearsonCorrelation: Pearson correlation matrix contains NaN values.\n"}], "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.stat import Correlation\n\ndata = [(Vectors.sparse(4, [(0, 1.0), (3, -2.0)]),),\n        (Vectors.dense([4.0, 5.0, 0.0, 3.0]),),\n        (Vectors.dense([6.0, 7.0, 0.0, 8.0]),),\n        (Vectors.sparse(4, [(0, 9.0), (3, 1.0)]),)]\ndf = spark.createDataFrame(data, [\"features\"])\n\nr1 = Correlation.corr(df, \"features\").head()\nprint(\"Pearson correlation matrix:\\n\" + str(r1[0]))\n\nr2 = Correlation.corr(df, \"features\", \"spearman\").head()\nprint(\"Spearman correlation matrix:\\n\" + str(r2[0]))"}, {"cell_type": "markdown", "id": "ae24cdac-c740-4066-acce-ddcb09fdc189", "metadata": {}, "source": "Find full example code at [\"examples/src/main/python/ml/chi_square_test_example.py\"](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/correlation_example.py) in the Spark repo."}, {"cell_type": "markdown", "id": "96061ae0-5fa2-4074-ac9c-c14ec50ca127", "metadata": {}, "source": "## Hypothesis Testing <a name=\"Hypothesis\"></a>\nHypothesis testing is a powerful tool in statistics to determine whether a result is statistically significant, whether this result occurred by chance or not. spark.ml currently supports Pearson\u2019s Chi-squared ( \u03c72\n) tests for independence.\n\n### ChiSquareTest <a name=\"ChiSquareTest\"></a>\nChiSquareTest conducts Pearson\u2019s independence test for every feature against the label. For each feature, the (feature, label) pairs are converted into a contingency matrix for which the Chi-squared statistic is computed. All label and feature values must be categorical.\n\nRefer to the [ChiSquareTest Python docs](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.stat.ChiSquareTest.html) for details on the API."}, {"cell_type": "code", "execution_count": 4, "id": "63e00482-c66f-456e-aadd-d96b6f5801a9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "pValues: [0.6872892787909721,0.6822703303362126]\ndegreesOfFreedom: [2, 3]\nstatistics: [0.75,1.5]\n"}], "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.stat import ChiSquareTest\n\ndata = [(0.0, Vectors.dense(0.5, 10.0)),\n        (0.0, Vectors.dense(1.5, 20.0)),\n        (1.0, Vectors.dense(1.5, 30.0)),\n        (0.0, Vectors.dense(3.5, 30.0)),\n        (0.0, Vectors.dense(3.5, 40.0)),\n        (1.0, Vectors.dense(3.5, 40.0))]\ndf = spark.createDataFrame(data, [\"label\", \"features\"])\n\nr = ChiSquareTest.test(df, \"features\", \"label\").head()\nprint(\"pValues: \" + str(r.pValues))\nprint(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\nprint(\"statistics: \" + str(r.statistics))"}, {"cell_type": "markdown", "id": "349acaf1-1e31-404a-b4cb-55edd6076b9a", "metadata": {}, "source": "Find full example code at [\"examples/src/main/python/ml/chi_square_test_example.py\"](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/chi_square_test_example.py) in the Spark repo."}, {"cell_type": "markdown", "id": "7b813a5d-2d08-43c1-a6ff-b594c6a0dee3", "metadata": {}, "source": "## Summarizer <a name=\"Summarizer\"></a>\nWe provide vector column summary statistics for Dataframe through Summarizer. Available metrics are the column-wise max, min, mean, sum, variance, std, and number of nonzeros, as well as the total count.\n\nRefer to the [Summarizer Python docs](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.stat.Summarizer.html) for details on the API."}, {"cell_type": "code", "execution_count": 5, "id": "3a834b73-06eb-4441-b718-f0b47a06e601", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------------------------+\n|aggregate_metrics(features, weight)|\n+-----------------------------------+\n|{[1.0,1.0,1.0], 1}                 |\n+-----------------------------------+\n\n+--------------------------------+\n|aggregate_metrics(features, 1.0)|\n+--------------------------------+\n|{[1.0,1.5,2.0], 2}              |\n+--------------------------------+\n\n+--------------+\n|mean(features)|\n+--------------+\n|[1.0,1.0,1.0] |\n+--------------+\n\n+--------------+\n|mean(features)|\n+--------------+\n|[1.0,1.5,2.0] |\n+--------------+\n\n"}], "source": "from pyspark.ml.stat import Summarizer\nfrom pyspark.sql import Row\nfrom pyspark.ml.linalg import Vectors\n\ndf = sc.parallelize([Row(weight=1.0, features=Vectors.dense(1.0, 1.0, 1.0)),\n                     Row(weight=0.0, features=Vectors.dense(1.0, 2.0, 3.0))]).toDF()\n\n# create summarizer for multiple metrics \"mean\" and \"count\"\nsummarizer = Summarizer.metrics(\"mean\", \"count\")\n\n# compute statistics for multiple metrics with weight\ndf.select(summarizer.summary(df.features, df.weight)).show(truncate=False)\n\n# compute statistics for multiple metrics without weight\ndf.select(summarizer.summary(df.features)).show(truncate=False)\n\n# compute statistics for single metric \"mean\" with weight\ndf.select(Summarizer.mean(df.features, df.weight)).show(truncate=False)\n\n# compute statistics for single metric \"mean\" without weight\ndf.select(Summarizer.mean(df.features)).show(truncate=False)"}, {"cell_type": "markdown", "id": "c1c1f285-ed77-4c2f-89c9-91ab94994667", "metadata": {}, "source": "Find full example code at [\"examples/src/main/python/ml/summarizer_example.py\"](https://github.com/apache/spark/blob/master/examples/src/main/python/ml/summarizer_example.py) in the Spark repo."}, {"cell_type": "code", "execution_count": null, "id": "0fb621c7-c722-41ad-ac9d-a4c8922236c2", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}