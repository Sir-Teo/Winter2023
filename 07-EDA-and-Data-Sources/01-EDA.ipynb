{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** This notebook might not run properly on a small cluster. It was tested on a 5-node cluster with e2-highmem-2 machines.\n",
        "\n",
        "Update the bucket name to your own:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = \"gs://pstat135/data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis or Data Profiling\n",
        "\n",
        "Data profiling should address the following topics:\n",
        "\n",
        "* Completeness: How complete is the data? What percentage of records has missing or null values?\n",
        "* Uniqueness: How many unique values does an attribute have? Does the attribute(s) that is supposed to be the unique key, have all unique values?\n",
        "* Distribution: What is the distribution of values of an attribute?\n",
        "* Basic statistics: The mean, standard deviation, minimum, maximum for numerical attributes.\n",
        "* Pattern matching: What patterns are matched by data values of an attribute?\n",
        "* Outliers: Are there outliers in the numerical data?\n",
        "* Correlation: What is the correlation between two given attributes? This kind of profiling may be important for feature analysis prior to building predictive models.\n",
        "\n",
        "The advantages of EDA can be summarized as:\n",
        "\n",
        "* Find out what is in the data before using it\n",
        "* Get data quality metrics\n",
        "* Get an early assessment on the difficulties in creating business rules\n",
        "* Input the a subsequent cleansing step\n",
        "* Discover value patterns and distributions\n",
        "* Understanding data challenges early to avoid delays and cost overruns\n",
        "* Improve the ability to search the data\n",
        "\n",
        "Following statistics are typically calculated:\n",
        "\n",
        "|Statistics|Description|\n",
        "|--|--|\n",
        "|Count|\tUsing the Dataframe describe method|\n",
        "|Average|\tUsing the Dataframe describe method|\n",
        "|Minimum|\tUsing the Dataframe describe method|\n",
        "|Maximum|\tUsing the Dataframe describe method|\n",
        "|Standard deviation|\tUsing the Dataframe describe method|\n",
        "|Missing values|\tUsing the Dataframe filter method|\n",
        "|Density|\tRatio calculation|\n",
        "|Min. string length|\tUsing the Dataframe expr, groupBy, agg, min, max, avg methods|\n",
        "|Max. string length|\tUsing the Dataframe expr, groupBy, agg, min, max, avg methods|\n",
        "|\\# uniques values|\tUsing the Dataframe distinct and count methods|\n",
        "|Top 100 of most frequent values|\tUsing the Dataframe groupBy, count, filter, orderBy, limit methods|\n",
        "\n",
        "\n",
        "Source: http://www.bigdatareflections.net/blog/?p=111\n",
        "\n",
        "# City of Chicago: Reported Crime Dataset - Since 2001\n",
        "\n",
        "**Data Source:** Dataset was downloaded from [data.cityofchicago.org](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2)\n",
        "\n",
        "This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. The dataset is being updated daily; the data used in this notebook was updated on March 21, 2021. Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims, addresses are shown at the block level only and specific locations are not identified.\n",
        "\n",
        "\n",
        "**Columns in this Dataset**\n",
        "\n",
        "|Column Name|Description|Type|\n",
        "|--|--|--|\n",
        "|ID|Unique identifier for the record.|String|\n",
        "|Case Number|The Chicago Police Department RD Number (Records Division Number), which is unique to the incident.|String|\n",
        "|Date|Date when the incident occurred. this is sometimes a best estimate.|Timestamp|\n",
        "|Block|The partially redacted address where the incident occurred, placing it on the same block as the actual address.|String|\n",
        "|IUCR|The Illinois Unifrom Crime Reporting code. This is directly linked to the Primary Type and Description. See the list of IUCR codes at https://data.cityofchicago.org/d/c7ck-438e.|String|\n",
        "|Primary Type|The primary description of the IUCR code.|String|\n",
        "|Description|The secondary description of the IUCR code, a subcategory of the primary description.|String|\n",
        "|Location Description|Description of the location where the incident occurred.|String|\n",
        "|Arrest|Indicates whether an arrest was made.|Boolean|\n",
        "|Domestic|Indicates whether the incident was domestic-related as defined by the Illinois Domestic Violence Act.|Boolean|\n",
        "|Beat|Indicates the beat where the incident occurred. A beat is the smallest police geographic area â€“ each beat has a dedicated police beat car. Three to five beats make up a police sector, and three sectors make up a police district. The Chicago Police Department has 22 police districts. See the beats at https://data.cityofchicago.org/d/aerh-rz74.|String|\n",
        "|District|Indicates the police district where the incident occurred. See the districts at https://data.cityofchicago.org/d/fthy-xz3r.|String|\n",
        "|Ward|The ward (City Council district) where the incident occurred. See the wards at https://data.cityofchicago.org/d/sp34-6z76.|String|\n",
        "|Community Area|Indicates the community area where the incident occurred. Chicago has 77 community areas. See the community areas at https://data.cityofchicago.org/d/cauq-8yn6.|String|\n",
        "|FBI Code|Indicates the crime classification as outlined in the FBI's National Incident-Based Reporting System (NIBRS).|String|\n",
        "|X Coordinate|The x coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block.|Double|\n",
        "|Y Coordinate|The y coordinate of the location where the incident occurred in State Plane Illinois East NAD 1983 projection. This location is shifted from the actual location for partial redaction but falls on the same block.|Double|\n",
        "|Year|Year the incident occurred.|Integer|\n",
        "|Updated On|Date and time the record was last updated.|Date|\n",
        "|Latitude|The latitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block.|Double|\n",
        "|Longitude|The longitude of the location where the incident occurred. This location is shifted from the actual location for partial redaction but falls on the same block.|Double|\n",
        "|Location|The location where the incident occurred in a format that allows for creation of maps and other geographic operations on this data portal. This location is shifted from the actual location for partial redaction but falls on the same block.|String|\n",
        "\n",
        "## Some of the questions one could ask and find answers to from this dataset:\n",
        "* How has crime in Chicago changed across years? \n",
        "* Was 2016 really the bloodiest year in two decades?\n",
        "* Are some types of crimes more likely to happen in specific locations or specific time of the day or specific day of the week than other types of crimes?\n",
        "\n",
        "### Loading the data into a Spark DataFrame\n",
        "We will first define our schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "from pyspark.sql.types import (StructType, \n",
        "                               StructField, \n",
        "                               DateType, \n",
        "                               BooleanType,\n",
        "                               DoubleType,\n",
        "                               IntegerType,\n",
        "                               StringType)\n",
        "\n",
        "crimes_schema = StructType([StructField(\"ID\", StringType(), True),\n",
        "                            StructField(\"CaseNumber\", StringType(), True),\n",
        "                            StructField(\"Date\", StringType(), True ),\n",
        "                            StructField(\"Block\", StringType(), True),\n",
        "                            StructField(\"IUCR\", StringType(), True),\n",
        "                            StructField(\"PrimaryType\", StringType(), True  ),\n",
        "                            StructField(\"Description\", StringType(), True ),\n",
        "                            StructField(\"LocationDescription\", StringType(), True ),\n",
        "                            StructField(\"Arrest\", BooleanType(), True),\n",
        "                            StructField(\"Domestic\", BooleanType(), True),\n",
        "                            StructField(\"Beat\", StringType(), True),\n",
        "                            StructField(\"District\", StringType(), True),\n",
        "                            StructField(\"Ward\", StringType(), True),\n",
        "                            StructField(\"CommunityArea\", StringType(), True),\n",
        "                            StructField(\"FBICode\", StringType(), True ),\n",
        "                            StructField(\"XCoordinate\", DoubleType(), True),\n",
        "                            StructField(\"YCoordinate\", DoubleType(), True ),\n",
        "                            StructField(\"Year\", IntegerType(), True),\n",
        "                            StructField(\"UpdatedOn\", StringType(), True ),\n",
        "                            StructField(\"Latitude\", DoubleType(), True),\n",
        "                            StructField(\"Longitude\", DoubleType(), True),\n",
        "                            StructField(\"Location\", StringType(), True )\n",
        "                            ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create crimes dataframe by providing the schema above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = spark.read.format(\"csv\")\\\n",
        "  .option(\"header\", \"true\")\\\n",
        "  .schema(crimes_schema)\\\n",
        "  .load(data + \"chicago-crimes/Crimes_2001_to_present.csv\")\n",
        "\n",
        "crimes.printSchema()\n",
        "crimes.show(1, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Caching the crimes DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = crimes.repartition(20)\n",
        "print(\"data was re-partitioned to {} partitions!\".format(crimes.rdd.getNumPartitions()))\n",
        "\n",
        "# Setting the number of shuffle partitions\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"20\")\n",
        "\n",
        "# Caching the DataFrame\n",
        "crimes.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "print(\" The crimes DataFrame has {} records\".format(crimes.count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dropping columns that we will not be using in our analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = crimes.drop('CaseNumber', 'IUCR', 'XCoordinate', 'YCoordinate', 'UpdatedOn','Year', 'Location')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Converting Date to timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = crimes.withColumn(\"Date\", F.to_timestamp(\"Date\", 'MM/dd/yyyy hh:mm:ss a'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dropping duplicates if any?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = crimes.drop_duplicates()\n",
        "crimes.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since this is a clean and well-maintained dataset there are no duplicates! The number matches the one before dropping duplicates!\n",
        "\n",
        "### Renaming column names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes = crimes.withColumnRenamed(\"Latitude\", \"Lat\")\\\n",
        "  .withColumnRenamed(\"Longitude\", \"Lon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.limit(3).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of the columns using `describe()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.describe(['Lat', 'Lon']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Date range:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.selectExpr(\"min(Date)\", \"max(Date)\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes_per_year = crimes.groupBy(F.year(\"Date\").alias(\"Year\")).agg(F.count(\"ID\").alias(\"crimes_count\")).orderBy(\"Year\")\n",
        "crimes_per_year.show(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Primary crime types\n",
        "How many primary crime types are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.select(\"PrimaryType\").distinct().count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rank them based on their frequency:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.groupBy(\"PrimaryType\").agg(F.count('ID').alias(\"Count\"))\\\n",
        "  .orderBy(F.desc(\"Count\")).show(35, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Domestic assaults\n",
        "How many domestic assaults are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.filter((crimes[\"PrimaryType\"] == \"ASSAULT\") & (crimes[\"Domestic\"] == True)).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arrest\n",
        "How often these crimes resulted in an arrest?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "total_arrests = crimes.where(F.col(\"Arrest\") == True).count()\n",
        "total_crime = crimes.count()\n",
        "\n",
        "print(\"{}% Arrests.\".format(round(total_arrests/total_crime*100, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "arrests_per_year = crimes.where(F.col(\"Arrest\") == True).groupBy(F.year(\"Date\").alias(\"Year\"))\\\n",
        "  .agg(F.count(\"ID\").alias(\"arrests_count\")).orderBy(\"Year\")\n",
        "\n",
        "arrest_rate = crimes_per_year.join(arrests_per_year, \"Year\")\\\n",
        "  .withColumn(\"arrest_rate\", F.round(F.col(\"arrests_count\")/F.col(\"crimes_count\")*100, 2))\\\n",
        "  .orderBy(\"Year\")\n",
        "\n",
        "arrest_rate.show(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What percentage of the crimes are domestic?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes.where(crimes[\"Domestic\"]==True).count()/crimes.count() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization in PySpark\n",
        "PySpark doesn't offer any visualization tool at the server level (at least yet!). In general we have three choices:\n",
        "* Aggregate the data in Spark and return the aggregate to Python for plotting\n",
        "* Sample our dataset to a smaller set that fits in driver's memory\n",
        "* Return the dataset to Python. Note that this option will only work with smaller datasets and can crash your driver's note if the number of data points are in millions or billions\n",
        "\n",
        "## Bar chart\n",
        "Let's use the `arrest_rate` DataFrame that we created above to plot a bar charts.\n",
        "\n",
        "We first need to convert our aggregated Spark DataFrame into a Pandas DataFrame. We can do this with we can use PySpark's `toPandas()` method on `arrest_rate`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "py_arrest_rate = arrest_rate.toPandas()\n",
        "py_arrest_rate.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use *matplotlib* for plotting, let's first load it in notebook mode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = py_arrest_rate.set_index('Year')\n",
        "\n",
        "df[[\"crimes_count\", \"arrests_count\"]].plot.bar()\n",
        "plt.title('Crimes & Arrests');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df['arrest_rate'].plot.bar()\n",
        "plt.title('Arrest Rate')\n",
        "plt.ylabel(\"Percentage of Arrests\", fontsize = 18);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histograms\n",
        "In the following we will plot a histogram using Spark's aggregation. \n",
        "\n",
        "Let's aggregate the data first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "hists = crimes.where(\"Lat > 37\").select(\"Lat\").rdd.flatMap(\n",
        "    lambda row: row\n",
        ").histogram(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To plot the histogram, you can simply call *matplotlib*, as shown in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'bins': hists[0][:-1],\n",
        "    'freq': hists[1]\n",
        "}\n",
        "\n",
        "plt.bar(data['bins'], data['freq'], width=.005)\n",
        "plt.xlabel(\"Latitude\")\n",
        "plt.title('Histogram of Latitude');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "hists = crimes.where(\"Lon > -90\").select(\"Lon\").rdd.flatMap(\n",
        "    lambda row: row\n",
        ").histogram(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'bins': hists[0][:-1],\n",
        "    'freq': hists[1]\n",
        "}\n",
        "\n",
        "plt.bar(data['bins'], data['freq'], width=.005)\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.title('Histogram of Longitude');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Line Plot\n",
        "Number of crimes by month:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes_for_each_month = crimes.groupBy(F.month(\"Date\").alias(\"Month\")).agg(F.count(\"ID\").alias(\"crimes_count\")).orderBy(\"Month\")\n",
        "\n",
        "# Convert to Pandas\n",
        "py_crimes_for_each_month = crimes_for_each_month.toPandas()\n",
        "py_crimes_for_each_month.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df = py_crimes_for_each_month.set_index('Month')\n",
        "df.plot.line()\n",
        "plt.ylabel(\"Number of Crimes\", fontsize = 14)\n",
        "plt.title('Number of Crimes for Each Month of the Year');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes_per_month = crimes.groupBy(F.date_format(F.col(\"Date\"), 'yyyy-MM').alias(\"Date\")).agg(F.count(\"ID\").alias(\"crimes_count\")).orderBy(\"Date\")\n",
        "\n",
        "# Convert to Pandas\n",
        "py_crimes_per_month = crimes_per_month.toPandas()\n",
        "py_crimes_per_month.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "df = py_crimes_per_month.set_index('Date')\n",
        "df.plot.line()\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Number of Crimes\", fontsize = 14)\n",
        "plt.title('Number of Crimes per Month');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling & Scatterplot\n",
        "In the following cell we sample 0.1% of the data to plot a scatterplot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "crimes_sample = crimes.sample(withReplacement = False, fraction = 0.005, seed = 42)\n",
        "\n",
        "# Convert to Pandas\n",
        "py_crimes_sample = crimes_sample.toPandas()\n",
        "\n",
        "py_crimes_sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(py_crimes_sample['Lon'], py_crimes_sample['Lat'], alpha=0.01)\n",
        "plt.xlim(-87.95, -87.5)\n",
        "plt.ylim(41.6, 42.05);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/soltaniehha/Big-Data-Analytics-for-Business/blob/master/figs/07-01-Chicago.png?raw=true\" width=\"600\" align=\"left\"/>\n",
        "\n",
        "## Further investigations on the dataset\n",
        "See if you can ask more questions and find answers to those by looking at the data. Here are a few suggestions:\n",
        "\n",
        "* Where do most crimes take pace?\n",
        "* Which days have the highest number of crimes?\n",
        "* Number of domestic crimes by hour?\n",
        "* Number of 'MOTOR VEHICLE THEFT' from `PrimaryType` column by hour?\n",
        "* What is the trend of 'LIQUOR LAW VIOLATION' from `PrimaryType` like over the past 10 years?\n",
        "* Do you see any changes during the COVID-19 pandemic on different crime types? \n",
        "    * It is very likely that mandatory quarantines caused increase in dmoestic violence categories and decrease in robbery. Could you find any evidence in the data?\n",
        "\n",
        "Related EDA work on this dataset:\n",
        "* https://www.kaggle.com/fahd09/eda-of-crime-in-chicago-2005-2016\n",
        "* https://datascienceplus.com/spark-dataframes-exploring-chicago-crimes/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Your answer goes here"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
